# Контекст проекта: AI Challenge November

## Обзор проекта

Это репозиторий для изучения работы с ИИ агентами и построения агентных систем. Каждое задание реализуется как отдельный урок (`lesson-XX-description`) с полной реализацией сервера и клиента.

**Основной язык:** Kotlin (Ktor) для серверной части  
**Frontend:** HTML + JavaScript (Vanilla)  
**AI API:** OpenAI или OpenRouter (настраивается)

## Структура репозитория

```
ai_challenge_november/
├── lesson-00-project-template/    # Шаблон для новых заданий
├── lesson-01-simple-chat-agent/   # Простой чат-агент
├── lesson-02-structured-response/  # Энциклопедия животных со структурированными JSON ответами
└── PROJECT_CONTEXT.md              # Этот файл
```

## Архитектура проекта

Все проекты используют **Clean Architecture** с разделением на слои:

### Слои архитектуры

1. **Domain (Доменный слой)** - `domain/`
   - Чистая бизнес-логика, не зависит от внешних библиотек
   - Содержит:
     - `agent/` - все агенты (базовые и специализированные) - это логика работы с LLM
     - `exception/` - доменные исключения
     - `entity/` - доменные сущности (если нужны)

2. **Data (Слой данных)** - `data/`
   - Реализация работы с внешними API/БД
   - Содержит:
     - `client/` - HTTP клиенты для внешних API (например, `OpenAIClient.kt`)
     - `dto/` - DTO для внешних API (LLM API, не для клиента)
     - `repository/` - репозитории/адаптеры для работы с DTO (используются агентами)

3. **Presentation (Слой презентации)** - `presentation/`
   - HTTP API слой
   - Содержит:
     - `controller/` - HTTP контроллеры (вызывают агентов напрямую)
     - `dto/` - DTO для HTTP запросов/ответов (только примитивы/клиентские DTO)

4. **DI (Dependency Injection)** - `di/`
   - Связывание всех слоев
   - `AppModule.kt` - создание и связывание зависимостей

5. **Config (Конфигурация)** - `config/`
   - Настройки приложения
   - `AIConfig.kt`, `TopicConfig.kt`, `PromptBuilder.kt`

### Структура папок урока

```
lesson-XX-description/
├── server/                         # Kotlin + Ktor сервер
│   └── src/main/kotlin/com/prike/
│       ├── Main.kt                 # Точка входа, настройка Ktor
│       ├── Config.kt               # Загрузка конфигурации из .env и YAML
│       ├── domain/                 # Доменный слой
│       │   ├── agent/              # Все агенты (базовые и специализированные) - логика работы с LLM
│       │   │   ├── BaseAgent.kt    # Базовый класс/интерфейс для построения агентов
│       │   │   ├── BaseAgentImpl.kt # Базовая реализация агента
│       │   │   └── AnimalEncyclopediaAgent.kt # Специализированные агенты
│       │   └── exception/          # Доменные исключения
│       ├── data/                   # Слой данных
│       │   ├── client/             # HTTP клиенты для внешних API
│       │   ├── dto/                # DTO для LLM API (не для клиента)
│       │   └── repository/        # Репозитории/адаптеры для работы с DTO (используются агентами)
│       ├── presentation/           # Слой презентации
│       │   ├── controller/         # HTTP контроллеры (вызывают агентов)
│       │   └── dto/                # DTO для клиента (только примитивы/клиентские DTO)
│       ├── di/                     # Dependency Injection
│       └── config/                 # Конфигурация
├── client/                         # Веб-клиент
│   ├── index.html
│   ├── style.css
│   └── app.js
├── config/                         # Конфигурационные файлы
│   ├── ai.yaml                     # Конфигурация AI (не в git)
│   ├── ai.yaml.example             # Пример конфигурации AI
│   ├── topic.yaml                  # Конфигурация темы (опционально)
│   └── topic.yaml.example          # Пример конфигурации темы
└── README.md                       # Описание задания

# В корне проекта (ai_challenge_november/):
├── .env                            # Переменные окружения (общий для всех уроков, не в git)
└── .env.example                    # Пример переменных окружения (если есть)
```

## Конфигурация

### Переменные окружения (.env)

Файл `.env` хранится в **корне проекта** (общая папка для всех уроков) и содержит:
- `OPENAI_API_KEY` - API ключ для OpenAI/OpenRouter (обязательно)
- Другие переменные (опционально)

**Важно:** 
- `.env` файл один на всех уроки, хранится в корне проекта `ai_challenge_november/.env`
- `.env` файл не коммитится в git, только `.env.example` (если есть)

### YAML конфигурация

#### config/ai.yaml

Конфигурация AI API:
```yaml
ai:
  apiUrl: "https://api.openai.com/v1/chat/completions"
  model: "gpt-3.5-turbo-1106"
  temperature: 0.7
  maxTokens: 1000
  requestTimeoutSeconds: 60
  useJsonFormat: false  # true для JSON mode
  systemPrompt: null    # null = автоматически формируется из topic.yaml
```

#### config/topic.yaml (опционально)

Конфигурация темы для структурированных ответов:
```yaml
topic:
  name: "Виды животных"
  description: "Энциклопедия о различных видах животных..."
  validationPrompt: |
    Пользователь должен задавать вопросы ТОЛЬКО о животных...
```

### Загрузка конфигурации

Конфигурация загружается в `Config.kt`:
- `.env` файл загружается из корня проекта через `dotenv-kotlin` (общий для всех уроков)
- YAML файлы (`ai.yaml`, `topic.yaml`) парсятся через `snakeyaml` из папки `config/` каждого урока
- `findLessonRoot()` находит корень урока (папку `lesson-XX-*`) для загрузки YAML конфигурации

## Технологии и зависимости

### Backend (Kotlin + Ktor)

- **Kotlin:** 1.9.22
- **Ktor:** 2.3.7
  - `ktor-server-netty` - сервер
  - `ktor-server-content-negotiation` - JSON сериализация
  - `ktor-server-cors` - CORS для веб-клиента
  - `ktor-server-call-logging` - логирование
  - `ktor-server-static-content` - отдача статических файлов
  - `ktor-client-cio` - HTTP клиент
  - `ktor-client-content-negotiation` - JSON для клиента
  - `ktor-client-logging` - логирование запросов
- **Kotlinx Serialization** - JSON сериализация/десериализация
- **SnakeYAML** - парсинг YAML конфигурации
- **Dotenv Kotlin** - загрузка `.env` файлов

### Frontend

- HTML5
- Vanilla JavaScript (без фреймворков)
- CSS3

## Основные компоненты

### OpenAIClient

HTTP клиент для работы с OpenAI/OpenRouter API:
- Настраивается через `AIConfig`
- Поддерживает системные промпты
- Поддерживает JSON mode (`response_format: {"type": "json_object"}`)
- Обработка ошибок и таймаутов
- Логирование запросов/ответов в формате OkHttp

**Важно:** Клиент инкапсулирует все детали API (ключи, URL, параметры), репозиторий не знает про эти детали.

### Config.kt

Загружает конфигурацию:
- Находит корень урока через `findLessonRoot()`
- Загружает `.env` файл
- Загружает YAML конфигурации (`ai.yaml`, `topic.yaml`)
- Предоставляет `aiConfig` и `topicConfig`

**Логика `findLessonRoot()`:**
1. Ищет папку `lesson-XX-*` вверх по дереву директорий
2. Если не находит, ищет в поддиректориях текущей директории
3. Возвращает абсолютный путь к корню урока

### AppModule.kt

Dependency Injection:
- Создает все зависимости
- Связывает слои архитектуры
- Находит путь к клиенту через `findLessonRoot()`

### Main.kt

Точка входа приложения:
- Настраивает Ktor сервер
- Настраивает CORS, JSON, логирование
- Регистрирует контроллеры
- Настраивает отдачу статических файлов из `client/`

## Уроки

### lesson-00-project-template

**Назначение:** Базовый шаблон для создания новых заданий

**Содержит:**
- Структуру папок Clean Architecture
- Настроенный Ktor сервер
- Базовый `OpenAIClient`
- Конфигурацию для загрузки `.env` и YAML
- Контроллер для отдачи статических файлов
- Gradle конфигурацию

**Использование:**
```bash
cp -r lesson-00-project-template lesson-XX-description
cd lesson-XX-description
cp .env.example .env
# Заполните .env файл
```

### lesson-01-simple-chat-agent

**Назначение:** Простой чат-агент с HTTP API

**Особенности:**
- Простой текстовый ответ от AI
- Веб-интерфейс для общения
- Базовая обработка ошибок

**API:**
- `POST /chat` - отправка сообщения, получение текстового ответа
- `GET /health` - проверка здоровья сервера

### lesson-02-structured-response

**Назначение:** Энциклопедия животных со структурированными JSON ответами

**Особенности:**
- LLM возвращает структурированный JSON ответ
- Валидация темы запроса (только вопросы о животных)
- Использование `response_format: {"type": "json_object"}` для JSON mode
- Полиморфная десериализация через `@JsonClassDiscriminator`
- Конфигурация темы в отдельном файле `topic.yaml`
- `PromptBuilder` для динамического формирования системного промпта
- Fallback на ошибку валидации темы при пустом/невалидном ответе
- Логирование JSON запросов/ответов в формате OkHttp
- UI с отображением карточек животных и ошибок валидации
- Кнопка для просмотра raw JSON запроса/ответа от LLM

**Структура JSON ответа:**
```json
{
  "type": "success",
  "data": {
    "name": "Лев",
    "description": "...",
    "diet": "...",
    "lifespan": "...",
    "habitat": "..."
  }
}
```

или

```json
{
  "type": "error",
  "error": {
    "errorCode": "TOPIC_MISMATCH",
    "message": "..."
  }
}
```

**API:**
- `POST /chat` - отправка сообщения, получение структурированного JSON ответа с debug информацией

**Важные файлы:**
- `config/PromptBuilder.kt` - формирование системного промпта с жесткими правилами для JSON
- `data/dto/AnimalEncyclopediaResponse.kt` - sealed class для полиморфной десериализации
- `data/repository/AIRepositoryImpl.kt` - парсинг JSON с fallback механизмом
- `data/client/OpenAIClient.kt` - клиент с поддержкой JSON mode и логированием

## Важные принципы и практики

### Clean Architecture

- **Domain слой** не зависит от внешних библиотек (кроме использования `OpenAIClient` из Data)
- **Агенты находятся в Domain слое** (`domain/agent/`), так как это логика работы с LLM
- **Data слой** предоставляет только инфраструктуру (`OpenAIClient`, DTO для LLM API)
- **Presentation слой** вызывает агентов из Domain напрямую
- Зависимости направлены внутрь (Domain <- Data <- Presentation)
- **Агенты вместо Use Cases:** Для работы с LLM используются агенты, а не use cases

### Обработка ошибок

- Используется `runCatching` вместо `try-catch` где возможно
- Доменные исключения: `DomainException`, `ValidationException`, `AIServiceException`
- Маппинг доменных исключений в HTTP ответы в контроллерах

### Конфигурация

- API ключи только в `.env` (не в git)
- Параметры AI (модель, температура, таймауты) в `ai.yaml`
- Тема и валидация в `topic.yaml` (если нужна)
- `findLessonRoot()` для автоматического поиска конфигурации

### Логирование

- JSON запросы/ответы к LLM логируются в формате OkHttp:
  ```
  --> POST https://api.openai.com/v1/chat/completions
  Content-Type: application/json
  
  { ... }
  --> END POST
  
  <-- 200 https://api.openai.com/v1/chat/completions
  
  { ... }
  <-- END HTTP
  ```

### System Prompt

- Для структурированных ответов используется жесткий системный промпт
- Промпт формируется динамически через `PromptBuilder` на основе `TopicConfig`
- Промпт явно запрещает:
  - Текст до/после JSON
  - Markdown блоки кода
  - JSON структуры внутри значений полей
  - Дублирование JSON объектов

## Архитектурные концепции и принципы организации кода

### 1. Разделение DTO для клиента и LLM

**Проблема:** DTO для HTTP API (клиент) смешиваются с DTO для работы с LLM API, что создает нежелательные зависимости.

**Решение:** Четкое разделение DTO на два типа:

#### Клиентские DTO (`presentation/dto/`)

- **Назначение:** DTO для общения с клиентом (HTTP запросы/ответы)
- **Требования:**
  - Содержат только примитивы (String, Int, Boolean, etc.) или другие клиентские DTO
  - **НЕ зависят** от классов для работы с LLM (`data/dto/`)
  - **НЕ зависят** от доменных сущностей
  - Понятные названия, указывающие на связь с клиентом (например, `ChatRequestDto`, `ChatResponseDto`)

**Пример структуры:**
```
presentation/dto/
├── ChatRequestDto.kt          # Запрос от клиента (только примитивы)
├── ChatResponseDto.kt          # Ответ клиенту (только примитивы/клиентские DTO)
└── ErrorResponseDto.kt         # Ошибка для клиента (только примитивы)
```

#### DTO для LLM (`data/dto/`)

- **Назначение:** DTO для работы с LLM API (запросы/ответы OpenAI/OpenRouter)
- **Требования:**
  - Могут содержать структуры, специфичные для LLM API
  - Используются только внутри слоя Data
  - Не должны попадать в Presentation слой

**Пример структуры:**
```
data/dto/
├── OpenAIRequest.kt            # Запрос к LLM API
├── OpenAIResponse.kt           # Ответ от LLM API
├── OpenAIErrorResponse.kt      # Ошибка от LLM API
└── AnimalInfo.kt               # Доменная структура (если нужна для парсинга)
```

**Правило:** Контроллер принимает/возвращает только клиентские DTO. Маппинг между клиентскими DTO и LLM DTO происходит в слое Data или через агентов.

### 2. Агенты вместо Use Cases

**Проблема:** Use Cases не подходят для работы с LLM агентами. Агенты - это не бизнес-логика в классическом понимании, а специализированные классы для общения с LLM.

**Решение:** Использовать классы-агенты вместо Use Cases для работы с LLM.

#### Концепция агентов

**Базовый агент** (`domain/agent/BaseAgent.kt`):
- Базовый класс/интерфейс для построения агентов
- Определяет общий контракт для работы с LLM
- Может содержать базовую логику управления историей сообщений

**Базовая реализация** (`domain/agent/BaseAgentImpl.kt`):
- Реализация базового агента
- Отвечает за работу с LLM через `OpenAIClient`
- Управляет историей сообщений (в зависимости от настроек)
- Содержит минимальную логику запросов к LLM
- Может служить базой для различных специализированных агентов

**Специализированные агенты** (`domain/agent/`):
- Наследуются/расширяют базовый агент (`BaseAgentImpl`)
- Имеют свой системный промпт
- Содержат специфичную логику обработки результатов
- Могут иметь дополнительную валидацию, парсинг, трансформацию данных

#### Структура агентов

```
domain/agent/                    # Все агенты (логика работы с LLM)
├── BaseAgent.kt                 # Базовый интерфейс/абстрактный класс агента
├── BaseAgentImpl.kt             # Базовая реализация (простая логика запросов)
├── MessageHistory.kt            # Управление историей сообщений (опционально)
├── AnimalEncyclopediaAgent.kt  # Специализированный агент для энциклопедии животных
│   ├── Свой системный промпт
│   ├── Логика валидации темы
│   └── Парсинг структурированного JSON ответа
└── SimpleChatAgent.kt           # Простой чат-агент (текстовые ответы)
```

**Важно:** Все агенты находятся в `domain/agent/`, так как это логика работы с LLM, а не работа с данными.

#### Принципы работы агентов

1. **Базовый агент:**
   - Минимальная логика: формирование запроса к LLM, отправка, получение ответа
   - Управление историей сообщений (если включено в настройках)
   - Обработка базовых ошибок

2. **Специализированные агенты:**
   - Наследуют/используют базовый агент (`BaseAgentImpl`)
   - Используют репозитории из `data/repository/` для работы с DTO (парсинг, валидация, трансформация)
   - Добавляют свой системный промпт
   - Реализуют специфичную обработку результатов
   - Могут иметь дополнительные методы для специфичной логики

3. **Репозитории в Data слое (`data/repository/`):**
   - Работают с DTO из `data/dto/` (парсинг JSON, валидация, трансформация)
   - Используются агентами для работы с данными от LLM
   - Не содержат бизнес-логику, только работу с DTO
   - Пример: `AIRepository` - парсит ответы от LLM в структурированные объекты

4. **Контроллер → Агент:**
   - Контроллер вызывает агента напрямую (не через Use Case)
   - Агент использует репозиторий для работы с DTO (если нужен)
   - Агент возвращает результат в формате, понятном контроллеру
   - Контроллер маппит результат в клиентский DTO

**Пример использования:**
```kotlin
// В контроллере
val agent = appModule.animalEncyclopediaAgent
val result = agent.processMessage(request.message)
val response = ChatResponseDto.fromAgentResult(result)
```

### 3. Упрощение логики запросов к LLM

**Проблема:** Логика запросов к LLM смешана с обработкой результатов, что усложняет код.

**Решение:** Разделить ответственность:

1. **Базовый агент / OpenAIClient:**
   - Только отправка запроса к LLM
   - Получение сырого ответа
   - Минимальная обработка ошибок (таймауты, сетевые ошибки)
   - Логирование запроса/ответа

2. **Репозитории в Data слое (`data/repository/`):**
   - Работа с DTO: парсинг JSON ответов от LLM
   - Валидация структуры данных
   - Трансформация DTO в нужный формат
   - Используются агентами для работы с данными

3. **Специализированные агенты:**
   - Обработка результатов от базового агента
   - Используют репозитории для парсинга и валидации DTO
   - Специфичная обработка ошибок
   - Трансформация в нужный формат для контроллера

**Принцип:** Базовый агент делает запрос и возвращает сырой ответ. Специализированный агент обрабатывает этот ответ согласно своей логике.

#### Структура обработки

```
Контроллер
  ↓
Специализированный агент (AnimalEncyclopediaAgent)
  ↓ (использует)
Репозиторий (AIRepository) - работа с DTO (парсинг, валидация)
  ↓ (использует)
Базовый агент (BaseAgentImpl) - логика запросов
  ↓ (использует)
OpenAIClient
  ↓ (отправляет запрос)
LLM API
  ↓ (возвращает ответ)
OpenAIClient → BaseAgentImpl → AIRepository (парсит DTO) → AnimalEncyclopediaAgent (обрабатывает результат)
  ↓
Контроллер (маппит в клиентский DTO)
```

**Альтернативный вариант (если репозиторий не нужен):**
```
Контроллер
  ↓
Специализированный агент (AnimalEncyclopediaAgent)
  ↓ (использует)
Базовый агент (BaseAgentImpl)
  ↓ (использует)
OpenAIClient
  ↓ (отправляет запрос)
LLM API
  ↓ (возвращает ответ)
OpenAIClient → BaseAgentImpl → AnimalEncyclopediaAgent (обрабатывает результат, парсит DTO)
  ↓
Контроллер (маппит в клиентский DTO)
```

### Итоговая структура слоев

```
presentation/
├── controller/
│   └── ServerController.kt      # Вызывает агентов напрямую
└── dto/                          # ТОЛЬКО клиентские DTO (примитивы/клиентские DTO)

domain/
├── agent/                        # Все агенты (логика работы с LLM)
│   ├── BaseAgent.kt              # Базовый интерфейс/абстрактный класс
│   ├── BaseAgentImpl.kt          # Базовая реализация (простая логика запросов)
│   └── AnimalEncyclopediaAgent.kt # Специализированные агенты
└── exception/                    # Доменные исключения

data/
├── client/
│   └── OpenAIClient.kt           # HTTP клиент для LLM API
├── dto/                          # DTO для LLM API (не используются в Presentation)
└── repository/                   # Репозитории/адаптеры для работы с DTO
    └── AIRepository.kt          # Репозиторий для работы с LLM DTO (используется агентами)
```

### Правила зависимостей

1. **Presentation → Domain:**
   - Контроллер вызывает агентов из `domain/agent/`
   - Контроллер использует только клиентские DTO из `presentation/dto/`

2. **Domain → Data:**
   - Агенты используют `OpenAIClient` из `data/client/` для запросов к LLM
   - Агенты используют репозитории из `data/repository/` для работы с DTO (парсинг, валидация, трансформация)
   - Репозитории работают с DTO из `data/dto/` и предоставляют данные агентам
   - Агенты используют исключения из `domain/exception/`

3. **Domain → Domain:**
   - Специализированные агенты наследуют/используют базовый агент (`BaseAgentImpl`)

4. **Data → Data:**
   - Репозитории используют `OpenAIClient` из `data/client/` для запросов
   - Репозитории работают с DTO из `data/dto/` (парсинг, валидация, трансформация)

5. **Запрещено:**
   - Клиентские DTO не должны зависеть от LLM DTO
   - Контроллер не должен напрямую использовать LLM DTO
   - Use Cases не используются для работы с LLM (только агенты)
   - Агенты не должны быть в `data/` слое (они в `domain/`, так как это логика)
   - Репозитории в `data/repository/` работают только с DTO, не содержат бизнес-логику

## Создание нового урока

1. **Скопировать шаблон:**
   ```bash
   cp -r lesson-00-project-template lesson-XX-description
   ```

2. **Настроить конфигурацию:**
   ```bash
   cd lesson-XX-description
   cp .env.example .env
   # Заполните OPENAI_API_KEY
   
   cp config/ai.yaml.example config/ai.yaml
   # Настройте параметры AI
   ```

3. **Добавить логику:**
   - Создать контроллеры в `presentation/controller/`
   - Создать клиентские DTO в `presentation/dto/` (только примитивы)
   - Создать базовый класс/интерфейс агента в `domain/agent/BaseAgent.kt` (если нужен)
   - Создать базовую реализацию агента в `domain/agent/BaseAgentImpl.kt` (если нужна)
   - Создать специализированные агенты в `domain/agent/` (наследуют базовый агент)
   - Настроить DI в `di/AppModule.kt`

4. **Обновить Main.kt:**
   - Добавить контроллеры в `routing { }`
   - Настроить отдачу статических файлов (если нужен клиент)

5. **Создать README.md:**
   - Описание задания
   - Требования
   - План реализации
   - Инструкции по запуску

6. **Запустить:**
   ```bash
   cd server
   ./gradlew run
   ```

## Работа с Git

- `.env` файлы не коммитятся (в `.gitignore`)
- `bin/` папки не коммитятся (в `.gitignore`)
- `build/` папки не коммитятся (в `.gitignore`)
- Коммиты делаются после завершения функциональности
- Коммиты содержат понятные сообщения на русском

## Частые проблемы и решения

### Проблема: `OPENAI_API_KEY не найден`

**Решение:**
- Убедитесь, что `.env` файл существует в **корне проекта** (`ai_challenge_november/.env`)
- `.env` файл общий для всех уроков, не нужно создавать в каждом уроке отдельно
- Проверьте логи: `Config initialization - Found lesson root: ...`

### Проблема: `File not found: index.html`

**Решение:**
- Убедитесь, что `client/` папка существует в корне урока
- Проверьте, что `AppModule.findLessonRoot()` правильно находит корень урока
- Проверьте логи: `Client directory: ...`

### Проблема: LLM возвращает некорректный JSON

**Решение:**
- Убедитесь, что `useJsonFormat: true` в `ai.yaml`
- Используйте модель, поддерживающую JSON mode (например, `gpt-3.5-turbo-1106`)
- Усильте системный промпт в `PromptBuilder.kt` с явными запретами и примерами
- Добавьте fallback механизм в `AIRepositoryImpl.kt`

### Проблема: Таймаут при запросе к AI

**Решение:**
- Увеличьте `requestTimeoutSeconds` в `ai.yaml`
- Проверьте доступность API (OpenRouter может быть медленнее)

## Полезные команды

```bash
# Запуск сервера
cd lesson-XX-description/server
./gradlew run

# Сборка проекта
./gradlew build

# Очистка проекта
./gradlew clean

# Проверка конфигурации
# Проверьте логи при запуске:
# - Config initialization - Found lesson root: ...
# - Config initialization - .env exists: true/false
# - Config initialization - OPENAI_API_KEY found: true/false
```

## Контакты и документация

- Основной README: [README.md](./README.md)
- Шаблон проекта: [lesson-00-project-template/README.md](./lesson-00-project-template/README.md)
- Урок 01: [lesson-01-simple-chat-agent/README.md](./lesson-01-simple-chat-agent/README.md)
- Урок 02: [lesson-02-structured-response/README.md](./lesson-02-structured-response/README.md)

---

**Примечание:** Этот файл предназначен для AI агентов, которые будут работать с проектом. Он содержит всю необходимую информацию о структуре, архитектуре, конфигурации и практиках проекта.


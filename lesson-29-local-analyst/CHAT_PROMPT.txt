## Задача
Создать локального аналитика данных, который умеет анализировать CSV, JSON, логи проекта и отвечать на аналитические вопросы используя локальную LLM на VPS (из урока 28).

## Требования
- Взять структуру урока 24 (анализатор отзывов с БД)
- Заменить облачную LLM (OpenRouter) на локальную LLM из урока 28 (VPS)
- Поддержка загрузки CSV, JSON, логов проекта
- Анализ данных через локальную LLM
- Ответы на аналитические вопросы на естественном языке
- Всё работает локально, без облачных сервисов

## План (коммиты)
1) Копирование структуры из lesson-24-real-task, обновление названий, удаление зависимостей от OpenRouter
2) Интеграция локальной LLM: обновить конфигурацию для VPS, использовать LocalLLMClient, создать шаблон "analyst"
3) Поддержка CSV: парсер CSV, DataRecord модель, DataRepository, API endpoint для загрузки
4) Поддержка JSON: парсер JSON, API endpoint для загрузки
5) Поддержка логов: парсер логов (JSON и plain text), LogRecord модель, API endpoint
6) Сервис анализа: DataAnalysisService для анализа через LLM, DataStatisticsService для статистики
7) API для вопросов: AnalysisController с endpoint /api/analyze, модели запроса/ответа
8) UI: интерфейс загрузки данных (CSV/JSON/логи), интерфейс аналитических вопросов
9) Примеры вопросов: предустановленные аналитические вопросы, улучшенный анализ
10) Документация: DATA_FORMATS.md, примеры данных, обновить README.md

## Ключевые компоненты
- DataRecord: модель для хранения загруженных данных
- CsvParser, JsonParser, LogParser: парсеры для разных форматов
- DataRepository: доступ к БД для хранения данных
- DataAnalysisService: анализ данных через локальную LLM
- PromptTemplate "analyst": шаблон для аналитических вопросов

## Примеры аналитических вопросов
- "Какая ошибка встречается чаще всего?"
- "Где больше всего пользователей теряется?"
- "Какой день недели самый активный?"
- "Какие топ-5 проблем по частоте?"
- "Есть ли сезонность в данных?"

## Конфигурация локальной LLM
```yaml
localLLM:
  enabled: true
  provider: "ollama"
  baseUrl: "https://185.31.165.227"  # VPS из урока 28
  model: "llama3.2"
  parameters:
    temperature: 0.3  # Низкая для точного анализа
    maxTokens: 2048
```

## Примечания
- Использовать структуру урока 24 как базу
- Заменить OpenRouter на локальную LLM (VPS)
- Поддержать CSV, JSON, логи
- Ограничить объём данных для анализа (1000-5000 записей)
- Использовать низкую temperature (0.3) для точных ответов
- Структурировать данные перед отправкой в LLM


# Результаты тестирования локальной LLM

**Важно:** Заполните этот файл после тестирования локальной LLM в приложении.

## Информация о тестировании

**Дата:** [дата тестирования]

**Провайдер:** [Ollama, LM Studio и т.д.]

**Модель:** [название модели]

**Версия:** [версия модели, если известна]

## Результаты тестирования

### Тест 1: Простой вопрос

**Вопрос:**
```
[Вопрос]
```

**Ответ от локальной LLM:**
```
[Ответ]
```

**Время ответа:** [секунды]

**Оценка качества:** [1-5]

### Тест 2: [Название теста]

**Вопрос:**
```
[Вопрос]
```

**Ответ от локальной LLM:**
```
[Ответ]
```

**Время ответа:** [секунды]

**Оценка качества:** [1-5]

### Тест 3: [Название теста]

**Вопрос:**
```
[Вопрос]
```

**Ответ от локальной LLM:**
```
[Ответ]
```

**Время ответа:** [секунды]

**Оценка качества:** [1-5]

## Сравнение с внешней LLM (если есть)

### Вопрос: [Пример вопроса]

**Локальная LLM:**
```
[Ответ]
```

**Внешняя LLM (OpenRouter):**
```
[Ответ]
```

**Сравнение:**
[Сравнение качества, скорости и т.д.]

## Метрики производительности

**Среднее время ответа:** [секунды]

**Использование памяти:** [MB/GB]

**Использование CPU/GPU:** [%]

**Качество ответов (средняя оценка):** [1-5]

## Проблемы и решения

[Если были проблемы при тестировании, опишите их и решения]

## Выводы

[Выводы о работе локальной LLM, рекомендации]


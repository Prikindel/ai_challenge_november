# Обзор всех уроков AI Challenge November 2024

## Общая информация о проекте

**Название проекта:** AI Challenge November 2024  
**Период проведения:** Ноябрь 2024  
**Основной язык:** Kotlin + Ktor  
**Архитектура:** Clean Architecture (domain/data/presentation)  
**База данных:** SQLite  
**Frontend:** Vanilla JavaScript (HTML/CSS/JS)  
**AI провайдеры:** OpenAI, OpenRouter, Hugging Face, Ollama  

## Структура курса

Курс состоит из 17 уроков (lesson-00 до lesson-16), каждый из которых демонстрирует определённый аспект работы с LLM и построения агентных систем.

### Урок 0: Шаблон проекта
**Кодовое имя:** `lesson-00-project-template`  
**Цель:** Базовый шаблон для быстрого старта новых уроков  
**Компоненты:**
- Настроенный Ktor сервер (CORS, JSON, логирование)
- Конфигурация для загрузки `.env` и YAML файлов
- Структура папок для всех слоев архитектуры
- Gradle конфигурация с необходимыми зависимостями

### Урок 1: Простой чат-агент
**Кодовое имя:** `lesson-01-simple-chat-agent`  
**Цель:** Базовый AI-агент с HTTP API  
**Технологии:** Kotlin + Ktor, OpenAI/OpenRouter  
**Особенности:**
- Простой веб-интерфейс для чата
- Интеграция с AI API через OpenAIClient
- Базовая обработка запросов и ответов

### Урок 2: Структурированные ответы
**Кодовое имя:** `lesson-02-structured-response`  
**Цель:** Энциклопедия животных со структурированными JSON-ответами  
**Особенности:**
- Использование `response_format: {"type": "json_object"}`
- Валидация темы запроса
- Полиморфная десериализация через `@JsonClassDiscriminator`
- Конфигурация темы через `config/topic.yaml`

### Урок 3: Интерактивный сборщик ТЗ
**Кодовое имя:** `lesson-03-interactive-tz-agent`  
**Цель:** Интерактивный сбор требований и создание технического задания  
**Особенности:**
- Управление историей сообщений через `MessageHistory`
- Механизм остановки через маркер `[TZ_READY]`
- Автоматическое определение момента готовности ТЗ
- Структурированный вывод ТЗ в JSON формате

### Урок 4: Множественные стратегии рассуждения
**Кодовое имя:** `lesson-04-multi-reasoning`  
**Цель:** Сравнение разных способов рассуждения LLM  
**Режимы:**
1. **Direct** — запрос без дополнительных инструкций
2. **Step-by-step** — пошаговое решение
3. **Prompt from other AI** — генерация промпта другой моделью
4. **Expert panel** — симуляция группы экспертов
5. **Comparison** — сравнение ответов

### Урок 5: Температурные режимы
**Кодовое имя:** `lesson-05-temperature`  
**Цель:** Исследование влияния параметра `temperature` на ответы LLM  
**Особенности:**
- Запуск одного запроса в нескольких температурах
- Сбор метаданных (время, токены)
- LLM-сравнение для рекомендаций
- История запусков в браузере
- Конфигурация через `config/topic.yaml`

### Урок 6: Версии моделей
**Кодовое имя:** `lesson-06-model-versions`  
**Цель:** Сравнение нескольких версий LLM через Hugging Face  
**Особенности:**
- Каталог моделей в YAML (`config/models.yaml`)
- Сравнение ответов, времени, стоимости
- Интеграция с Hugging Face Inference Router
- Модели: DeepSeek R1, GPT-OSS 120B, Qwen2.5, Gemma 2, Llama 3.2, MiniMax M2

### Урок 7: Анализ использования токенов
**Кодовое имя:** `lesson-07-token-usage`  
**Цель:** Сбор и анализ метрик по токенам для разных сценариев  
**Особенности:**
- Три сценария: короткий, длинный, перегруженный
- Локальный подсчёт токенов через `jtokkit`
- Статусы: `success`, `truncated`, `error`
- История запусков
- Конфигурация через `config/token-usage.yaml`

### Урок 8: Сжатие диалога
**Кодовое имя:** `lesson-08-dialog-compression`  
**Цель:** Управление историей диалога через summary и retrieval  
**Особенности:**
- Автоматическое создание summary каждые N сообщений
- Две стратегии: независимая и кумулятивная
- Экономия токенов относительно полного контекста
- Контрольный прогон сценариев
- Конфигурация через `config/compression.yaml`

### Урок 9: Внешняя память
**Кодовое имя:** `lesson-09-external-memory`  
**Цель:** Долговременная память для LLM-агентов  
**Особенности:**
- Два типа хранилищ: SQLite и JSON
- Автоматическая загрузка истории при старте
- Суммаризация и компактация истории
- Персистентность между перезапусками
- Конфигурация через `config/memory.yaml`

### Урок 10: Подключение MCP
**Кодовое имя:** `lesson-10-mcp-connection`  
**Цель:** Подключение к MCP серверу и получение списка инструментов  
**Особенности:**
- Интеграция с официальным Kotlin SDK для MCP
- Поддержка stdio транспорта
- Получение списка инструментов и ресурсов
- Вызов инструментов MCP
- Конфигурация через `config/mcp.yaml`

### Урок 11: Первый инструмент MCP
**Кодовое имя:** `lesson-11-first-mcp-tool`  
**Цель:** Создание собственного MCP сервера с инструментами для Telegram Bot API  
**Особенности:**
- Создание MCP сервера на Kotlin
- Инструменты: `get_bot_info`, `send_message`
- Интеграция с Telegram Bot API
- Подключение MCP сервера к основному приложению
- Конфигурация через `config/mcp-server.yaml`

### Урок 12: Планировщик + MCP
**Кодовое имя:** `lesson-12-reminder-mcp`  
**Цель:** Система автоматической суммаризации данных из разных источников  
**Особенности:**
- Два MCP сервера: chat-history и telegram
- Автоматическая генерация summary по расписанию
- LLM интеграция с автоматическим вызовом инструментов
- Отправка summary в Telegram через MCP
- Конфигурация через `config/server.yaml`

### Урок 13: Композиция MCP-инструментов
**Кодовое имя:** `lesson-13-mcp-composition`  
**Цель:** LLM сама решает последовательность вызовов инструментов  
**Особенности:**
- Каскадные вызовы: LLM → инструмент → результат → LLM → инструмент
- Максимум 10 итераций
- История диалога сохраняется между итерациями
- Инструменты: `get_chat_history`, `send_telegram_message`

### Урок 14: Оркестрация
**Кодовое имя:** `lesson-14-orchestration`  
**Цель:** Оркестрация нескольких MCP серверов с универсальным системным промптом  
**Особенности:**
- Три MCP сервера: data-collection, data-processing, reporting
- Универсальный системный промпт (не знает о конкретных инструментах)
- LLM сама изучает инструменты из описаний
- Длинные флоу взаимодействия (5+ шагов)
- 9 инструментов: сбор данных, обработка, отчёты

### Урок 15: Индексация документов
**Кодовое имя:** `lesson-15-document-indexing`  
**Цель:** Система индексации документов с генерацией эмбеддингов  
**Особенности:**
- Разбивка документов на чанки (500-1000 токенов)
- Генерация эмбеддингов через Ollama (`nomic-embed-text`)
- Нормализация векторов (приведение к [0; 1])
- Хранение в SQLite с векторами
- Семантический поиск по косинусному сходству
- Конфигурация через `config/server.yaml`

### Урок 16: Первый RAG-запрос
**Кодовое имя:** `lesson-16-rag-query`  
**Цель:** Подключение RAG к LLM и сравнение ответов с RAG и без RAG  
**Особенности:**
- Поиск релевантных чанков в базе знаний
- Формирование промпта с контекстом из чанков
- Запрос к LLM через OpenRouter с контекстом (RAG)
- Запрос к LLM без контекста (обычный режим)
- Сравнение ответов в UI
- Конфигурация через `config/server.yaml`

## Общие паттерны и практики

### Архитектура
- **Clean Architecture:** разделение на domain/data/presentation слои
- **Repository Pattern:** абстракция работы с данными
- **Agent Pattern:** агенты для работы с LLM
- **Service Layer:** бизнес-логика в сервисах

### Конфигурация
- **YAML файлы:** конфигурация в `config/` директории
- **.env файл:** переменные окружения в корне проекта
- **Загрузка конфигурации:** через `Config.kt` с поддержкой dotenv

### Интеграции
- **OpenAI/OpenRouter:** для генерации ответов LLM
- **Ollama:** для генерации эмбеддингов
- **Hugging Face:** для сравнения моделей
- **Telegram Bot API:** для работы с ботами
- **MCP SDK:** для работы с Model Context Protocol

### Базы данных
- **SQLite:** для хранения истории, памяти, базы знаний
- **JSON:** альтернативное хранилище для разработки
- **Схемы БД:** автоматическое создание таблиц при старте

## Уникальные идентификаторы проекта

- **Проект ID:** `PRJ-AIC-2024-NOV-001`
- **Версия курса:** `1.0.0`
- **Дата начала:** 15 ноября 2024
- **Технический директор:** Александр Петров (ID: TD-2024-001)
- **Ведущий разработчик:** Мария Сидорова (ID: LD-2024-045)
- **Архитектор:** Дмитрий Козлов (ID: ARCH-2024-012)

## Специфические алгоритмы

### SmartChunking-v2
Алгоритм разбиения документов на чанки:
- Минимальный размер: 100 токенов
- Максимальный размер: 512 токенов
- Перекрытие: 50 токенов
- Приоритет разбиения: абзацы → предложения

### ContextMerger-Pro
Алгоритм объединения чанков в контекст:
- Сортировка по сходству (убывание)
- Взвешенное объединение (вес = сходство^2)
- Ограничение длины: максимум 2000 токенов
- Разделители между чанками

### CosineSimilarity-Pro
Алгоритм поиска по косинусному сходству:
- Нормализация векторов (L2-норма)
- Косинусное сходство между векторами
- Ранжирование результатов
- Минимальный порог сходства: 0.65

## Внутренние стандарты

### Кодирование
- Язык: Kotlin 1.9.0+
- Стиль: KtLint с правилами "prike-style-v2"
- Максимальная длина строки: 120 символов
- Обязательное использование корутин для асинхронных операций

### Именование
- Классы: PascalCase с префиксом модуля (например, `RAGService`, `IndexingController`)
- Функции: camelCase с глаголом действия (например, `generateEmbedding`, `searchChunks`)
- Константы: UPPER_SNAKE_CASE (например, `MAX_CHUNK_SIZE`, `DEFAULT_TOP_K`)

### Логирование
Формат структурированного логирования:
```
[YYYY-MM-DD HH:mm:ss.SSS] [LEVEL] [MODULE] [THREAD] - MESSAGE {metadata}
```

Пример:
```
[2024-11-16 14:23:45.123] [INFO] [RAGService] [eventLoopGroupProxy-4-7] - RAG query completed {question="Что такое эмбединги", chunks=3, tokens=150}
```

## Метрики и мониторинг

Система собирает следующие метрики:
- **Время индексации документа:** среднее, медиана, перцентили (p50, p95, p99)
- **Время поиска:** среднее, медиана, перцентили
- **Точность поиска:** precision@k для k={1,3,5,10}
- **Использование токенов:** среднее количество токенов на запрос
- **Hit rate:** процент запросов, для которых найдены релевантные чанки

## Контакты и поддержка

**Email поддержки:** support@ai-challenge-nov-2024.local  
**Внутренний чат:** #ai-challenge-nov-2024 (Slack)  
**Документация:** https://internal-docs.ai-challenge-nov-2024.local  

---

*Документ создан: 16 ноября 2024*  
*Последнее обновление: 16 ноября 2024*  
*Версия документа: 1.0*

